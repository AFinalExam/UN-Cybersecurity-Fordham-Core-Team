{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yxu190\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim import models,utils\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Cyber Security data.csv\",\n",
    "                encoding=\"windows-1252\")\n",
    "stop_words+=[i.lower() for i in df[\"Country\"].unique().tolist()]\n",
    "#stop_words+=[\"cyber\",\"secur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def Preprocess(text):\n",
    "    contents = [re.sub('[^a-zA-Z]',\" \",i) for i in text]\n",
    "    contents =[[i.lower() for i in sent.split() if i.lower() not in stop_words and len(i)>3] for sent in contents]\n",
    "    \n",
    "    words = []\n",
    "    for content in contents:\n",
    "        words+=content\n",
    "    \n",
    "    return contents,words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "contents,words = Preprocess(text = df[\"Sentence\"])\n",
    "tagged = [nltk.pos_tag(i) for i in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "stemmed_contents = [[PorterStemmer().stem(i[0]) for i in sent] for sent in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "stemmed_words = [PorterStemmer().stem(i) for i in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def word_removal(words_list,contents_list,most_common_num=None,least_num=None):\n",
    "    fd = FreqDist(words_list).most_common()\n",
    "    drops = [i[0] for i in fd[:most_common_num]]\n",
    "    drops.append([i[0] for i in fd if i[1]>least_num])\n",
    "    words2 = [[i for i in content if i not in drops] for content in contents_list]\n",
    "    return words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "inputHidden": true,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "tw = [nltk.pos_tag(i) for i in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "contents2 = word_removal(stemmed_words,stemmed_contents,5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "texts=contents2\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(line) for line in texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)\n",
    "tfidfs = [tfidf.__getitem__(i) for i in corpus]\n",
    "tfwords = [sorted(i,key=lambda x: x[1])[:3] for i in tfidfs]\n",
    "tfwords = [[i[0] for i in sent] for sent in tfwords]\n",
    "keys = dictionary.token2id.keys()\n",
    "values = dictionary.token2id.values()\n",
    "tfDic = dict()\n",
    "for i,j in zip(values,keys):\n",
    "    tfDic[i] = j\n",
    "tfwords = [[tfDic[i] for i in tfword ] for tfword in tfwords]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "texts=tfwords\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(line) for line in texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, update_every=1, chunksize=10000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.079*\"strategi\" + 0.049*\"support\" + 0.043*\"technolog\" + 0.041*\"implement\" + 0.040*\"commun\"'),\n",
       " (1,\n",
       "  '0.066*\"polici\" + 0.055*\"plan\" + 0.048*\"action\" + 0.048*\"cybersecur\" + 0.034*\"strategi\"'),\n",
       " (2,\n",
       "  '0.105*\"ensur\" + 0.063*\"level\" + 0.063*\"oper\" + 0.061*\"system\" + 0.057*\"govern\"'),\n",
       " (3,\n",
       "  '0.044*\"strategi\" + 0.034*\"increas\" + 0.032*\"object\" + 0.029*\"capabl\" + 0.027*\"societi\"'),\n",
       " (4,\n",
       "  '0.071*\"govern\" + 0.067*\"manag\" + 0.062*\"commun\" + 0.054*\"risk\" + 0.040*\"ministri\"'),\n",
       " (5,\n",
       "  '0.064*\"activ\" + 0.064*\"technolog\" + 0.029*\"process\" + 0.024*\"econom\" + 0.023*\"research\"'),\n",
       " (6,\n",
       "  '0.104*\"respons\" + 0.075*\"servic\" + 0.059*\"system\" + 0.038*\"sector\" + 0.034*\"public\"'),\n",
       " (7,\n",
       "  '0.142*\"intern\" + 0.076*\"sector\" + 0.065*\"also\" + 0.050*\"privat\" + 0.043*\"public\"'),\n",
       " (8,\n",
       "  '0.079*\"requir\" + 0.060*\"implement\" + 0.055*\"public\" + 0.041*\"system\" + 0.033*\"polici\"'),\n",
       " (9,\n",
       "  '0.101*\"protect\" + 0.070*\"infrastructur\" + 0.050*\"threat\" + 0.049*\"network\" + 0.046*\"includ\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(num_topics=10, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lda.save(\"UNlda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "topics = [sorted(lda.get_document_topics(corpus[i]),key=lambda x: x[1])[-1][0] for i in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Topic\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Document', 'Page', 'Sentence', 'Country', 'Unnamed: 5',\n",
       "       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop([\"Unnamed: 0\",\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\",\"Unnamed: 8\",\"Unnamed: 9\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"LDA_topics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "index = SparseMatrixSimilarity(lda[corpus],num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity,SparseMatrixSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "vec_lda = [lda[i] for i in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = [index[i] for i in vec_lda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5000):\n",
    "    s = [i for i in range(36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5000,10000):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10000,15000):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(15000,20000):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(20000,25000):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(25000,30000):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(25000,36517):\n",
    "    s = [i for i in range(j,36517) if sims[j][i]>0.99]\n",
    "    ms.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(ms)).to_csv(\"SimilaritySetenceIndex.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
